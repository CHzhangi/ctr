{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.1+cu121\n",
      "12.1\n",
      "8801\n",
      "True\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m data_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     21\u001b[0m df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(data_dir)  \n\u001b[1;32m---> 22\u001b[0m df_t\u001b[38;5;241m=\u001b[39m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_t)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# 将'user'特征赋值给my_object的user_feat属性\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.backends.cudnn.version())\n",
    "print(torch.cuda.is_available())\n",
    "data_dir='test.csv'\n",
    "df=pd.read_csv(data_dir)  \n",
    "df_t=torch.tensor(df.values,dtype=torch.float32)\n",
    "print(df_t)\n",
    "# 将'user'特征赋值给my_object的user_feat属性\n",
    "user_feat = torch.tensor(features['user']).reshape(-1,1)\n",
    "print(user_feat.size())\n",
    "if torch.cuda.is_available():  \n",
    "    print(\"CUDA is available. Training will be on GPU.\")  \n",
    "else:  \n",
    "    print(\"CUDA is not available. Training will be on CPU.\")\n",
    "\n",
    "datafile = 'housing.csv'\n",
    "housing_data = np.fromfile(datafile, sep=' ')\n",
    "feature_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE','DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "feature_num = len(feature_names)\n",
    "housing_data = housing_data.reshape([housing_data.shape[0] // feature_num, feature_num])\n",
    "features_np = np.array([x[:13] for x in housing_data], np.float32)\n",
    "labels_np = np.array([x[-1] for x in housing_data], np.float32)\n",
    "features_np = np.array([x[:13] for x in housing_data], np.float32)\n",
    "labels_np = np.array([x[-1] for x in housing_data], np.float32)\n",
    "# data_np = np.c_[features_np, labels_np]\n",
    "df = pd.DataFrame(housing_data, columns=feature_names)\n",
    "matplotlib.use('TkAgg')\n",
    "%matplotlib inline\n",
    "sns.pairplot(df.dropna(), y_vars=feature_names[-1], x_vars=feature_names[::-1], diag_kind='kde')\n",
    "plt.show()\n",
    "fig, ax = plt.subplots(figsize=(15, 1)) \n",
    "corr_data = df.corr().iloc[-1]\n",
    "corr_data = np.asarray(corr_data).reshape(1, 14)\n",
    "ax = sns.heatmap(corr_data, cbar=True, annot=True)\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(data=df.iloc[:, 0:13])\n",
    "plt.show()\n",
    "\n",
    "features_max = housing_data.max(axis=0)\n",
    "features_min = housing_data.min(axis=0)\n",
    "features_avg = housing_data.sum(axis=0) / housing_data.shape[0]\n",
    "#计算每一列的均值minmax也就是每个特征的\n",
    "\n",
    "def feature_norm(input):\n",
    "    f_size = input.shape\n",
    "    output_features = np.zeros(f_size, np.float32)\n",
    "    for batch_id in range(f_size[0]):\n",
    "        for index in range(13):\n",
    "            output_features[batch_id][index] = (input[batch_id][index] - features_avg[index]) / (features_max[index] - features_min[index])\n",
    "    return output_features \n",
    "\n",
    "# 只对属性进行归一化\n",
    "housing_features = feature_norm(housing_data[:, :13])\n",
    "# print(feature_trian.shape)\n",
    "housing_data = np.c_[housing_features, housing_data[:, -1]].astype(np.float32)\n",
    "# print(training_data[0])\n",
    "\n",
    "# 归一化后的train_data, 看下各属性的情况\n",
    "features_np = np.array([x[:13] for x in housing_data],np.float32)\n",
    "labels_np = np.array([x[-1] for x in housing_data],np.float32)\n",
    "data_np = np.c_[features_np, labels_np]\n",
    "df = pd.DataFrame(data_np, columns=feature_names)\n",
    "sns.boxplot(data=df.iloc[:, 0:13])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "def draw_train_process(iters, train_costs):\n",
    "    plt.title(\"training loss\", fontsize=24)\n",
    "    plt.xlabel(\"iter\", fontsize=14)\n",
    "    plt.ylabel(\"loss\", fontsize=14)\n",
    "    plt.plot(iters, train_costs, color='red', label='training cost')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "class myDataset(Dataset):\n",
    "    def __init__(self,csv_file):\n",
    "        self.data=pd.read_csv(csv_file).iloc[:,0].str.split().apply(pd.to_numeric, errors='coerce')\n",
    "        #.apply(pd.to_numeric, errors='coerce') 针对是str的\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self,index):\n",
    "        sample= self.data.iloc[index]\n",
    "        features=torch.tensor(sample[0:-1], dtype=torch.float32)\n",
    "        label=torch.tensor(sample[-1], dtype=torch.float32)\n",
    "        return features,label\n",
    "    \n",
    "input_n=13\n",
    "hidden_n=30\n",
    "output_n=1\n",
    "\n",
    "\n",
    "#model=nn.Sequential(\n",
    "#    nn.Linear(input_n,1)\n",
    "#    nn.Relu()\n",
    "#)\n",
    "\n",
    "\n",
    "class DNNnet(nn.Module):\n",
    "    def __init__(self,input_n,hidden_n,output_n):\n",
    "        super(DNNnet,self).__init__()\n",
    "        self.hidden=nn.Linear(input_n,hidden_n)\n",
    "        self.output=nn.Linear(hidden_n,output_n)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.hidden(x))\n",
    "        return self.output(x)\n",
    "criterion_DNN=nn.MSELoss()  \n",
    "#loss=criterion_DNN(prediction,y)  \n",
    "\n",
    "class LiRnet(nn.Module):\n",
    "    def __init__(self,input_n):\n",
    "        super(LiRnet,self).__init__()\n",
    "        self.Linear=nn.Linear(input_n,1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.Linear(x)\n",
    "        return x\n",
    "\n",
    "class LRnet(nn.Module):\n",
    "    def __init__(self,input_n):\n",
    "        super(LRnet,self).__init__()\n",
    "        self.Linear=nn.Linear(input_n,1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.Linear(x))\n",
    "        return self.sigmoid(x)\n",
    "    \n",
    "class SoftMaxNet(nn.Module):\n",
    "    def __init__(self,in_n,hi_n,o_n):\n",
    "        super(SoftMaxNet,self).__init__()\n",
    "        self.hidden=nn.Linear(in_n,hi_n)\n",
    "        self.output=nn.Linear(hi_n,o_n)\n",
    "    \n",
    "    def forward(self,X):\n",
    "        X=F.relu(self.hidden(x,hidden_n))\n",
    "        return self.output(x)\n",
    "criterion_Soft_LR = nn.CrossEntropyLoss()\n",
    "#loss=criterion_Soft_LR(prediction,y)\n",
    "\n",
    "net=LiRnet(input_n)\n",
    "\n",
    "optimizer=optim.Adam(net.parameters(),lr=0.01)\n",
    "#优化器\n",
    "\n",
    "data_dir='housing.csv'        \n",
    "data_set=myDataset(data_dir)\n",
    "#读取数据集\n",
    "\n",
    "train_size = int(0.8 * len(data_set))\n",
    "test_size = len(data_set) - train_size\n",
    "train_set, test_set = torch.utils.data.random_split(data_set, [train_size, test_size])\n",
    "#分割数据集为训练集和测试集\n",
    "\n",
    "df = pd.read_csv(data_dir,header=None)\n",
    "batch_size = 20\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "# 创建训练集和测试集的数据加载器\n",
    "\n",
    "n_epochs=10000\n",
    "#迭代次数\n",
    "\n",
    "Loss_func=nn.MSELoss()\n",
    "train_num=0\n",
    "train_nums=[]\n",
    "losses=[]\n",
    "print(next(net.parameters()).device)  \n",
    "#每次epoch都会遍历完一遍所有数据，一次train_loader会取batch_size样本\n",
    "for epoch in range(n_epochs):\n",
    "    for x,y in train_loader:\n",
    "        prediction=net(x)\n",
    "        loss=Loss_func(prediction,y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_num+=1\n",
    "        train_nums.append(train_num)\n",
    "        losses.append(loss.item())\n",
    "    if epoch % 10==0:\n",
    "            print(\"NO\", epoch, \"loss is %.2f\" % loss.item())\n",
    "matplotlib.use('TkAgg')\n",
    "%matplotlib inline\n",
    "draw_train_process(train_nums, losses)\n",
    "            \n",
    "with torch.no_grad():\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for x, y in test_loader:\n",
    "        prediction = DNNnet(x)\n",
    "        loss = Loss_func(prediction, y)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(prediction.data, 1)\n",
    "        total += y.size(0)\n",
    "        correct += (predicted == y).sum().item()\n",
    "\n",
    "    average_loss = test_loss / len(test_loader)\n",
    "    accuracy = correct / total * 100\n",
    "\n",
    "    print(\"Test Loss: %.2f\" % average_loss)\n",
    "    print(\"Accuracy: %.2f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(data_dir)\n\u001b[0;32m      3\u001b[0m array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(df)\n\u001b[1;32m----> 4\u001b[0m tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "data_dir = 'test.csv'\n",
    "df = pd.read_csv(data_dir)\n",
    "array = np.array(df)\n",
    "tensor = torch.tensor(array, dtype=torch.float64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
